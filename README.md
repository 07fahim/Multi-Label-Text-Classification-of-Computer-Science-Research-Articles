# Computer Science Research Article Subject Classifier

A **multi-label classification project** that predicts Computer Science subjects (e.g., _Machine Learning (cs.LG)_, _Artificial Intelligence (cs.AI)_) based on paper abstracts.

The pipeline includes:
- Scraping **~30,000 papers (2023â€“2025)** using Selenium  
- Training **SciBERT**, **DistilBERT**, and **DeBERTa-v3-small**
- Selecting **SciBERT** for deployment due to superior performance
- Converting the model to **ONNX** for optimized inference
- Deploying via **Flask on Render** with **Docker & GitHub Actions CI/CD** and **Gradio on Hugging Face Spaces**

---

---

## Table of Contents

- [Project Overview](#project-overview)
- [Branches](#branches)
- [Dataset](#dataset)
- [Model Training](#model-training)
- [Model Performance](#model-performance)
- [ONNX Conversion](#onnx-conversion)
- [Flask Web App](#flask-web-app)
- [Deployment](#deployment)
  - [Hugging Face Spaces](#deployment-on-hugging-face-spaces)
  - [Render with Docker & CI/CD](#deployment-on-render-with-docker--cicd)
- [Installation](#installation)
- [Usage](#usage)
- [Directory Structure](#directory-structure)
- [Technologies Used](#technologies-used)
- [Contributing](#contributing)
- [License](#license)
- [Links](#-links)

---

---

## Project Overview

This project classifies arXiv papers into multiple Computer Science subjects using their **abstracts**.

### Key Steps

1. **Data Collection** â€” Scraped ~30,000 papers using Selenium  
2. **Preprocessing** â€” Cleaned abstracts and subjects, filtered rare subjects  
3. **Model Training** â€” Trained SciBERT, DistilBERT, DeBERTa-v3-small  
4. **Model Selection** â€” Chose SciBERT for best performance  
5. **ONNX Conversion** â€” Exported model for optimized inference (reduced size from 421 MB to 110 MB)  
6. **Deployment** â€” Hosted on Render (with Docker & GitHub Actions) and Hugging Face Spaces

---

## Branches

| Branch | Description |
|:--|:--|
| **main** | Data scraping, preprocessing, model training, ONNX conversion and Deploying on Gradio on Hugging Face Spaces |
| **flask** | Flask web app with Docker containerization and CI/CD pipeline for Render deployment |

---

## Dataset

- **Source:** [arXiv.org](https://arxiv.org)  
- **Category:** Computer Science (cs)  
- **Years:** 2023â€“2025 (~10,000 papers/year, total ~30,000)  

**Fields:** `title`, `abstract`, `subjects`, `url`, `authors`

**Preprocessing:**
- Removed LaTeX, URLs, punctuation; converted to lowercase  
- Parsed subjects into full names (e.g., *Computation and Language (cs.CL)*)  
- Filtered rare subjects:
  - **Initial subjects:** 141
  - **Rare subjects removed:** 103
  - **Final subjects:** 38 (threshold = 0.005)
- Saved subject encodings to `subject_types_encoded.json`

---

## Model Training

Trained three models using **FastAI** + **blurr**:

| Model | Parameters | Source |
|:--|:--:|:--|
| **SciBERT** | ~110M | `allenai/scibert_scivocab_uncased` |
| **DistilBERT** | ~66M | `distilbert-base-uncased` |
| **DeBERTa-v3-small** | ~44M | `microsoft/deberta-v3-small` |

### Training Configuration

- **Max length:** 512 tokens  
- **Loss:** `BCEWithLogitsLossFlat`
- **Metrics:** Accuracy (thresh=0.2), F1 (micro/macro)
- **Training Stages:**
  - **Stage 0:** Train classifier head (frozen) â€” 2 epochs  
  - **Stage 1:** Fine-tune entire model â€” 3â€“5 epochs  

---

## Model Performance

| Model | Parameters | Valid Loss | Accuracy | F1 Score (Micro) | Training Time/Epoch |
|:--|:--:|:--:|:--:|:--:|:--:|
| **SciBERT** âœ… | ~110M | **0.0672** | **0.9743** | **0.5513** | ~4m 22s |
| **DistilBERT** | ~66M | 0.0761 | 0.9708 | 0.3881 | ~2m 23s |
| **DeBERTa-v3-small** | ~44M | 0.0764 | 0.9707 | 0.3867 | ~2m 23s |

### Why SciBERT?

**SciBERT** was selected for deployment based on:

1. **Domain-Specific Pretraining** â€” Trained on 1.14M scientific papers, providing better understanding of academic abstracts
2. **Superior F1 Score** â€” 0.5513 vs 0.3881 (DistilBERT) and 0.3867 (DeBERTa), representing **42-43% improvement**
3. **Lowest Validation Loss** â€” 0.0672 indicates better generalization
4. **Specialized Vocabulary** â€” Scientific terms and notation for better technical concept representation

**Trade-off:** Longer training time (4m 22s vs ~2m 23s), justified by substantial performance gains for classifying 38 Computer Science subjects.

---

## ONNX Conversion

Converted SciBERT to ONNX for efficient inference with quantization.

### File Size Comparison

| Format | Size | Reduction |
|:--|:--:|:--:|
| **PyTorch Model** | 421.3 MB | - |
| **ONNX (FP32)** | 424.7 MB | - |
| **ONNX Quantized (INT8)** | 110.3 MB | **74%** |

### Benefits

- **Faster Inference** â€” Optimized runtime performance
- **Reduced Size** â€” INT8 quantization (424.7 MB â†’ 110.3 MB)
- **Cross-Platform** â€” Deploy on various frameworks and devices
- **Production Ready** â€” Industry-standard format

---

## Flask Web App

Flask app (in `flask` branch) allows users to input an **abstract** and receive **predicted subjects**.

### Features
- Input: Abstract via HTML form  
- Output: Top 5 subjects with confidence scores  
- Caching: In-memory cache for repeated queries
- API: Gradio Client API for inference
- Concurrent processing with timeout handling

**Files:**
```
flask/
â”œâ”€â”€ app.py                    # Flask application with caching
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ home.html            # Landing page
â”‚   â”œâ”€â”€ index.html           # Classifier form
â”‚   â”œâ”€â”€ result.html          # Results display
â”‚   â””â”€â”€ about.html           # Project information
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ style.css            # Cyberpunk theme styling
â”‚   â””â”€â”€ bg-image.png         # Background image
â”œâ”€â”€ Dockerfile               # Docker containerization
â”œâ”€â”€ .dockerignore           # Docker ignore rules
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ render.yaml            # Render deployment config
```

---

## Deployment

### Deployment on Hugging Face Spaces

Deploy a Gradio interface on Hugging Face Spaces for interactive demos.

**Steps:**

1. Create a new Space on [Hugging Face Spaces](https://huggingface.co/spaces)
2. Select **Gradio** as the SDK
3. Use files from `deployment/` folder:

```
deployment/
â”œâ”€â”€ app.py                    # Gradio application
â”œâ”€â”€ requirements.txt          # Dependencies
â”œâ”€â”€ README.md                 # Space documentation
```

ğŸ”— **Try it here:** ğŸ‘‰ [Live Demo](https://huggingface.co/spaces/yeager07/multi-label-cs-article-classification)

<img src="assets/images/gradio_app.png" width="900" height="450">

---

### Deployment on Render with Docker & CI/CD

Deploy the Flask app on Render using **Docker** with automated **GitHub Actions** CI/CD pipeline.

#### ğŸ³ Docker Setup

The application is containerized using Docker for consistent deployment across environments.

**Dockerfile Features:**
- Python 3.12 slim base image
- Optimized layer caching
- Gunicorn WSGI server
- Health checks
- Non-root user for security

```dockerfile
FROM python:3.12-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 10000

CMD ["gunicorn", "-b", "0.0.0.0:10000", "--workers", "2", "--threads", "4", "--timeout", "120", "app:app"]
```

#### ğŸš€ CI/CD Pipeline

Automated deployment using **GitHub Actions** that triggers on every push to `flask` branch.

**Workflow Features:**
- Automatic Docker image building
- Push to Docker Hub registry
- Trigger Render deployment via webhook
- Build caching for faster deployments

**GitHub Actions Workflow** (`.github/workflows/deploy.yml`):

```yaml
name: Deploy to Render

on:
  push:
    branches:
      - flask
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: ${{ secrets.DOCKER_USERNAME }}/cs-article-classifier:latest

      - name: Trigger Render deployment
        run: curl -X POST ${{ secrets.RENDER_DEPLOY_HOOK_URL }}
```

#### ğŸ“‹ Setup Instructions

**1. GitHub Secrets Configuration**

Add these secrets to your GitHub repository (Settings â†’ Secrets and variables â†’ Actions):

| Secret | Description |
|--------|-------------|
| `DOCKER_USERNAME` | Your Docker Hub username |
| `DOCKER_PASSWORD` | Docker Hub access token |
| `RENDER_DEPLOY_HOOK_URL` | Render deploy webhook URL |

**2. Docker Hub Setup**

1. Create account at [hub.docker.com](https://hub.docker.com)
2. Create repository: `cs-article-classifier`
3. Generate access token (Account Settings â†’ Security â†’ New Access Token)

**3. Render Setup**

**Option A: Using Blueprint (Recommended)**
1. Go to [Render Dashboard](https://dashboard.render.com)
2. New â†’ Blueprint
3. Connect GitHub repository
4. Render auto-detects `render.yaml`
5. Click "Apply"

**Option B: Manual Setup**
1. New â†’ Web Service
2. Connect GitHub repository
3. Configure:
   - **Environment:** Docker
   - **Branch:** flask
   - **Dockerfile Path:** ./Dockerfile
   - **Instance Type:** Free
4. Add environment variables:
   - `PORT` = `10000`
   - `FLASK_ENV` = `production`

**4. Get Deploy Hook**
1. Service Settings â†’ Deploy Hook
2. Generate and copy URL
3. Add to GitHub Secrets as `RENDER_DEPLOY_HOOK_URL`

#### ğŸ”„ Deployment Process

**Automatic:**
```bash
# Make changes and push
git add .
git commit -m "Update application"
git push origin flask

# GitHub Actions automatically:
# 1. Builds Docker image
# 2. Pushes to Docker Hub
# 3. Triggers Render deployment
```

**Manual:**
1. Go to GitHub Actions tab
2. Select "Deploy to Render" workflow
3. Click "Run workflow"

#### ğŸ“Š Monitoring

- **GitHub Actions:** View build logs in Actions tab
- **Render Dashboard:** Monitor deployment status and logs
- **Health Check:** `https://your-app.onrender.com/`

#### ğŸ› Troubleshooting

**Build fails:**
```bash
# Test locally
docker build -t cs-classifier .
docker run -p 10000:10000 cs-classifier
```

**Deployment issues:**
- Check Render logs
- Verify environment variables
- Confirm port configuration (10000)
- Check Docker Hub image exists

ğŸ”— **Live App:** ğŸ‘‰ [multi-label-cs-article-classifier.onrender.com](https://multi-label-computer-science-article.onrender.com/)

<img src="assets/images/demo1.png" width="900" height="450">
<img src="assets/images/demo2.png" width="900" height="450">

---

## Installation

### Prerequisites
- Python â‰¥ 3.8    
- Git  
- Docker (for containerized deployment)
- Hugging Face account

### Steps

```bash
# Clone repository
git clone https://github.com/yeager07/Multi-Label-CS-Article-Classification.git
cd Multi-Label-CS-Article-Classification

# Install dependencies
pip install -r requirements.txt
```

**requirements.txt**
```
flask
werkzeug==2.3.0
gradio_client
gunicorn==20.1.0
```

---

## Usage

### Data Collection & Training (main branch)

```bash
# Train and export model using Jupyter notebooks
jupyter notebook
```

### Flask App (flask branch)

**Local Development:**
```bash
git checkout flask
python app.py
# Visit http://localhost:5000
```

**Docker:**
```bash
docker build -t cs-classifier .
docker run -p 10000:10000 cs-classifier
# Visit http://localhost:10000
```

---

## Directory Structure

```
Multi-Label-Computer-Science-Article-Classifier/
â”œâ”€â”€ main (branch)
â”‚   â”œâ”€â”€ data/                     # Dataset files
â”‚   â”œâ”€â”€ deployment/               # Hugging Face Spaces deployment
â”‚   â”‚   â”œâ”€â”€ app.py
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ models/                   # Trained models
â”‚   â”œâ”€â”€ notebooks/                # Training notebooks
â”‚   â”œâ”€â”€ src/                      # Source code
â”‚   â”‚   â”œâ”€â”€ scraper.py
â”‚   â”‚   â””â”€â”€ merge_data.py
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ requirements.txt
â”‚
â””â”€â”€ flask (branch)
    â”œâ”€â”€ .github/
    â”‚   â””â”€â”€ workflows/
    â”‚       â””â”€â”€ deploy.yml        # GitHub Actions CI/CD
    â”œâ”€â”€ static/                   # CSS and assets
    â”‚   â”œâ”€â”€ style.css
    â”‚   â””â”€â”€ bg-image.png
    â”œâ”€â”€ templates/                # HTML templates
    â”‚   â”œâ”€â”€ home.html
    â”‚   â”œâ”€â”€ index.html
    â”‚   â”œâ”€â”€ result.html
    â”‚   â””â”€â”€ about.html
    â”œâ”€â”€ .dockerignore            # Docker ignore rules
    â”œâ”€â”€ .gitignore
    â”œâ”€â”€ Dockerfile               # Docker configuration
    â”œâ”€â”€ app.py                   # Flask application
    â”œâ”€â”€ render.yaml              # Render blueprint
    â”œâ”€â”€ README.md
    â””â”€â”€ requirements.txt
```

---

## Technologies Used

### Machine Learning
- **SciBERT** (allenai/scibert_scivocab_uncased)
- **FastAI** 2.7.17 + blurr
- **PyTorch**
- **Transformers** library
- **ONNX Runtime** (optimization)

### Web Framework
- **Flask** (Backend API)
- **Gradio** (Interactive demo)
- **HTML/CSS** (Frontend)
- **Gunicorn** (WSGI server)

### DevOps & Deployment
- **Docker** (Containerization)
- **GitHub Actions** (CI/CD pipeline)
- **Render** (Flask hosting)
- **Hugging Face Spaces** (Gradio hosting)

### Data Processing
- **Pandas** (Data manipulation)
- **Selenium** (Web scraping)
- **JSON** (Data serialization)

---

## Contributing

Contributions are welcome!

1. Fork the repository
2. Create a feature branch: `git checkout -b feature-branch`
3. Commit changes: `git commit -m "Add new feature"`
4. Push and create PR: `git push origin feature-branch`

---

## ğŸ“„ License

This project is licensed under the MIT License.

---

## ğŸ”— Links

- **Live Flask App:** [multi-label-cs-article-classifier.onrender.com](https://multi-label-computer-science-article.onrender.com/)
- **Gradio Demo:** [HuggingFace Spaces](https://huggingface.co/spaces/yeager07/multi-label-cs-article-classification)
- **GitHub Repository:** [Multi-Label-CS-Article-Classification](https://github.com/yeager07/Multi-Label-CS-Article-Classification)

---

ğŸŒŸ **If you like this project, give it a star on GitHub!**
